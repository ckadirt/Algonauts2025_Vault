---
title: "Meeting: {{Meeting Title}}"
date: 2025-01-31
type: meeting
tags:
  - meeting
---

**

Cesar:

Potential way to organize: [https://github.com/ckadirt/Algonauts2025_Vault](https://github.com/ckadirt/Algonauts2025_Vault) [https://mellifluous-flan-118ac6.netlify.app/](https://mellifluous-flan-118ac6.netlify.app/)

  

Mihir:

[https://github.com/PaulScotti/algonauts2025/tree/mihir](https://github.com/PaulScotti/algonauts2025/tree/mihir)

- fMRI tokenization via VQ-VAE
    

- Tokenized fMRI → integrate with LLMs
    
- N_tokens = 32
    
- Variance: 0.65. (Goal: 0.85)
    

  

- MLP-based simple model
    

- Concat video, audio, language features
    
- Learnable language token
    
- Heavy overfitting, consistent with MLP based systems
    
- Pearson_corr: 0.211 (Subject 1, season 7).
    

  

- Data pipeline on github: [https://github.com/PaulScotti/algonauts2025/tree/main](https://github.com/PaulScotti/algonauts2025/tree/main)
    

  
  
  

Probably better way to evaluate OOD: train just on friends 1-6 and evaluate on movie 10.

- Features:
    

Different encoders. Whisper, V-jepa, Dino V2, Flan T5

	- Architecture:
	RNNs maybe?

- Window stimuli:
	Original is 5. Try increasing and decreasing this, and what happens when we use future features.
- More data:
	- Prepare preprocessing pipeline code (voxels to parcels)
	- [https://www.cneuromod.ca/](https://www.cneuromod.ca/) there is videogames data.
- Train a shared subject model.

Connor:

- fMRI tokenization (low priority, more risky)
- long context features with transformers (medium priority, once we 
- long context was important in Algonauts 2023.
- can leverage long context by training transformer on a sequence of (num_modalities * num_frames + 1, dim), where the last token is a cls for predicting the 1000 parcel activity.
- Alternatively, there's a possibility that different networks will need to attend to different features, e.g. the visual network will attend more to the vision features. The 1000 parcels can be partitioned into functional network clusters. Indeed, these networks are already defined (see Yeo 7 or 17 networks). We could then append n CLS tokens for predicting each of the n networks independently, and then combine the predictions.
- Would need modality specific linear projection from modality feature dim to the shared embedding dim. (The baseline uses pca, but I would just learn in the model end to end.)
- the idea is that we can use attention to efficiently find the relevant signal in the feature history that is relevant for prediction
- cf look at what Huze did to incorporate long context features [https://github.com/huzeyann/MemoryEncodingModel](https://github.com/huzeyann/MemoryEncodingModel)
